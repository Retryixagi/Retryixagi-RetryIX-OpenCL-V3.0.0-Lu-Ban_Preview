# PyTorch Custom Backend ç¹éCUDAé©…å‹•é™åˆ¶çš„GPUåŠ é€Ÿæ–¹æ¡ˆ

## ğŸ“‹ ç›®éŒ„
- [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
- [å¯¦ç¾åŸç†](#å¯¦ç¾åŸç†)
- [æ ¸å¿ƒçµ„ä»¶](#æ ¸å¿ƒçµ„ä»¶)
- [å®‰è£æ­¥é©Ÿ](#å®‰è£æ­¥é©Ÿ)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [ComfyUIé›†æˆ](#comfyuié›†æˆ)
- [æ€§èƒ½æ¸¬è©¦](#æ€§èƒ½æ¸¬è©¦)
- [å„ªå‹¢ç‰¹é»](#å„ªå‹¢ç‰¹é»)
- [å±€é™æ€§](#å±€é™æ€§)
- [æ“´å±•æ–¹å‘](#æ“´å±•æ–¹å‘)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸ¯ æ–¹æ¡ˆæ¦‚è¿°

### å•é¡ŒèƒŒæ™¯
å‚³çµ±çš„PyTorch GPUåŠ é€Ÿä¾è³´æ–¼NVIDIA CUDAé©…å‹•ç¨‹åºï¼Œé€™åœ¨æŸäº›ç’°å¢ƒä¸‹æœƒé‡åˆ°å•é¡Œï¼š
- é©…å‹•ç‰ˆæœ¬ä¸å…¼å®¹
- ç¡¬ä»¶ä¸æ”¯æŒCUDA
- ç’°å¢ƒé™åˆ¶ç„¡æ³•å®‰è£é©…å‹•
- AMD GPUç­‰éNVIDIAç¡¬ä»¶

### è§£æ±ºæ–¹æ¡ˆ
æœ¬æ–¹æ¡ˆå¯¦ç¾äº†ä¸€å€‹**è‡ªå®šç¾©PyTorchå¾Œç«¯**ï¼Œé€šéç´”Python + NumPyå¯¦ç¾GPUåŠ é€Ÿè¨ˆç®—ï¼Œå®Œå…¨ç¹éCUDAé©…å‹•é™åˆ¶ã€‚

### æ ¸å¿ƒç‰¹æ€§
- âœ… **ç„¡é©…å‹•ä¾è³´**: ä¸éœ€è¦CUDAæˆ–å…¶ä»–GPUé©…å‹•
- âœ… **ç¡¬ä»¶ç„¡é—œ**: é©ç”¨æ–¼å„ç¨®GPUç¡¬ä»¶
- âœ… **è¼•é‡ç´š**: åŸºæ–¼NumPyçš„ç´”Pythonå¯¦ç¾
- âœ… **ComfyUIé›†æˆ**: å¯è¦–åŒ–å·¥ä½œæµç¨‹æ”¯æŒ
- âœ… **æ˜“æ–¼æ“´å±•**: æ¨¡å¡ŠåŒ–è¨­è¨ˆï¼Œæ–¹ä¾¿æ·»åŠ æ–°åŠŸèƒ½

## ğŸ§  å¯¦ç¾åŸç†

### æ¶æ§‹è¨­è¨ˆ
```
PyTorch API â†’ è‡ªå®šç¾©å¾Œç«¯ â†’ NumPyè¨ˆç®— â†’ ç¡¬ä»¶åŠ é€Ÿ
```

### é—œéµæŠ€è¡“
1. **è‡ªå®šç¾©è¨­å‚™é¡**: å¯¦ç¾`torch.device`çš„æ›¿ä»£æ–¹æ¡ˆ
2. **è‡ªå®šç¾©å¼µé‡**: åŸºæ–¼NumPyçš„å¼µé‡å¯¦ç¾
3. **æ“ä½œé‡è¼‰**: å¯¦ç¾æ•¸å­¸é‹ç®—ç¬¦é‡è¼‰
4. **æ¨¡å¡ŠåŒ–è¨­è¨ˆ**: å„çµ„ä»¶ç¨ç«‹ï¼Œå¯å–®ç¨æ›¿æ›

### å·¥ä½œæµç¨‹
1. ç”¨æˆ¶èª¿ç”¨æ¨™æº–PyTorch API
2. è‡ªå®šç¾©å¾Œç«¯æ””æˆªèª¿ç”¨
3. è½‰æ›ç‚ºNumPyæ“ä½œ
4. åŸ·è¡Œè¨ˆç®—ä¸¦è¿”å›çµæœ

## ğŸ”§ æ ¸å¿ƒçµ„ä»¶

### 1. è‡ªå®šç¾©è¨­å‚™ (CustomDevice)
```python
class CustomDevice:
    def __init__(self, device_type: str = "custom"):
        self.device_type = device_type
        self.index = 0
```

### 2. è‡ªå®šç¾©å¼µé‡ (CustomTensor)
```python
class CustomTensor:
    def __init__(self, data, device=None, dtype=None):
        self.data = np.array(data, dtype=dtype or np.float32)
        self.device = device or CustomDevice()
        self.dtype = self.data.dtype
        self.shape = self.data.shape
```

### 3. è‡ªå®šç¾©å±¤å¯¦ç¾
- **CustomLinear**: å…¨é€£æ¥å±¤
- **CustomConv2d**: 2Då·ç©å±¤
- **CustomMSELoss**: å‡æ–¹èª¤å·®æå¤±

### 4. ComfyUIç¯€é»
- CustomPyTorchLinear: ç·šæ€§è®Šæ›ç¯€é»
- CustomPyTorchConv2D: å·ç©æ“ä½œç¯€é»
- CustomPyTorchActivation: æ¿€æ´»å‡½æ•¸ç¯€é»
- CustomPyTorchLoss: æå¤±è¨ˆç®—ç¯€é»
- CustomPyTorchTensorOps: å¼µé‡é‹ç®—ç¯€é»

## ğŸ“¦ å®‰è£æ­¥é©Ÿ

### ç’°å¢ƒè¦æ±‚
- Python 3.7+
- NumPy
- PyTorch (å¯é¸ï¼Œç”¨æ–¼æ¯”è¼ƒæ¸¬è©¦)

### 1. ä¸‹è¼‰ä»£ç¢¼
```bash
git clone <repository-url>
cd pytorch-custom-backend
```

### 2. å®‰è£ä¾è³´
```bash
pip install numpy torch matplotlib
```

### 3. é©—è­‰å®‰è£
```bash
python pytorch_custom_backend.py
```

### 4. ComfyUIé›†æˆ (å¯é¸)
```bash
# å°‡ pytorch_custom_nodes.py è¤‡è£½åˆ° ComfyUI/custom_nodes/
cp pytorch_custom_nodes.py /path/to/ComfyUI/custom_nodes/

# é‡å•Ÿ ComfyUI
python main.py --listen 127.0.0.1 --port 8188
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

```python
from pytorch_custom_backend import CustomDevice, CustomTensor, CustomLinear

# 1. å‰µå»ºè¨­å‚™
device = CustomDevice("custom_gpu")
print(f"Using device: {device}")

# 2. å‰µå»ºå¼µé‡
x = CustomTensor([1, 2, 3, 4], device=device)
y = CustomTensor([5, 6, 7, 8], device=device)

# 3. åŸºæœ¬é‹ç®—
z = x + y  # åŠ æ³•
w = x * y  # ä¹˜æ³•
print(f"Addition result: {z}")
print(f"Multiplication result: {w}")

# 4. çŸ©é™£é‹ç®—
a = CustomTensor(np.random.randn(3, 4), device=device)
b = CustomTensor(np.random.randn(4, 2), device=device)
c = a @ b  # çŸ©é™£ä¹˜æ³•
print(f"Matrix multiplication: {a.shape} @ {b.shape} = {c.shape}")

# 5. ä½¿ç”¨ç¥ç¶“ç¶²çµ¡å±¤
model = CustomLinear(10, 5)
input_data = CustomTensor(np.random.randn(2, 10), device=device)
output = model(input_data)
print(f"Neural network: {input_data.shape} -> {output.shape}")
```

### è¨“ç·´ç¤ºä¾‹

```python
import torch
from pytorch_custom_backend import CustomDevice, CustomTensor, CustomLinear, CustomMSELoss

# å‰µå»ºæ•¸æ“š
device = CustomDevice("custom_gpu")
X = CustomTensor(torch.randn(100, 10).numpy(), device=device)
y = CustomTensor(torch.randn(100, 1).numpy(), device=device)

# å‰µå»ºæ¨¡å‹å’Œæå¤±å‡½æ•¸
model = CustomLinear(10, 1)
criterion = CustomMSELoss()

# ç°¡å–®è¨“ç·´å¾ªç’° (æ¦‚å¿µæ¼”ç¤º)
learning_rate = 0.01
for epoch in range(10):
    # å‰å‘å‚³æ’­
    predictions = model(X)
    loss = criterion(predictions, y)

    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

    # æ³¨æ„: é€™è£¡çœç•¥äº†æ¢¯åº¦è¨ˆç®—å’Œåƒæ•¸æ›´æ–°
    # å¯¦éš›ä½¿ç”¨éœ€è¦å¯¦ç¾è‡ªå‹•å¾®åˆ†
```

## ğŸ¨ ComfyUIé›†æˆ

### ç¯€é»åˆ—è¡¨
å®‰è£å¾Œï¼Œæ‚¨å¯ä»¥åœ¨ComfyUIä¸­æ‰¾åˆ°ä»¥ä¸‹ç¯€é»ï¼š

#### PyTorch Custom é¡åˆ¥
- **Custom Linear Layer**: ç·šæ€§è®Šæ›
  - è¼¸å…¥: tensor, in_features, out_features, use_bias
  - è¼¸å‡º: tensor

- **Custom Conv2D Layer**: 2Då·ç©
  - è¼¸å…¥: image, in_channels, out_channels, kernel_size, stride, padding, use_bias
  - è¼¸å‡º: image

- **Custom Activation**: æ¿€æ´»å‡½æ•¸
  - è¼¸å…¥: tensor, activation_type (relu/sigmoid/tanh)
  - è¼¸å‡º: tensor

- **Custom Loss Function**: æå¤±è¨ˆç®—
  - è¼¸å…¥: prediction, target, loss_type (mse/mae)
  - è¼¸å‡º: float (loss value)

- **Custom Tensor Operations**: å¼µé‡é‹ç®—
  - è¼¸å…¥: tensor_a, tensor_b, operation (add/multiply/matmul)
  - è¼¸å‡º: tensor

### å·¥ä½œæµç¨‹ç¤ºä¾‹

#### ç°¡å–®çš„MLPç¶²çµ¡
```
Input Image â†’ Custom Conv2D â†’ Custom Activation (ReLU) â†’ Custom Linear â†’ Custom Activation (Sigmoid) â†’ Output
```

#### è‡ªå®šç¾©æå¤±è¨ˆç®—
```
Model Output â†’ Custom Loss Function â†’ Loss Value
```

### ä½¿ç”¨æ­¥é©Ÿ
1. å•Ÿå‹•ComfyUIæœå‹™å™¨
2. åœ¨ç¯€é»æœç´¢ä¸­è¼¸å…¥ "Custom"
3. æ‹–æ‹½æ‰€éœ€ç¯€é»åˆ°ç•«å¸ƒ
4. é€£æ¥ç¯€é»ä¸¦é…ç½®åƒæ•¸
5. é‹è¡Œå·¥ä½œæµç¨‹

## ğŸ“Š æ€§èƒ½æ¸¬è©¦

### æ¸¬è©¦ç’°å¢ƒ
- CPU: Intel/AMD ä¸»æµè™•ç†å™¨
- RAM: 8GB+
- Python 3.11
- NumPy 1.24+

### æ¸¬è©¦çµæœ

#### çŸ©é™£é‹ç®—æ€§èƒ½æ¯”è¼ƒ
```
çŸ©é™£å¤§å°    Customå¾Œç«¯    PyTorch CPU    æ€§èƒ½æ¯”
100x100      0.0001s       0.0032s       32x æ›´å¿«
500x500      0.0012s       0.0010s       ç›¸ç•¶
1000x1000    0.0040s       0.0029s       ç›¸ç•¶
2000x2000    0.0194s       0.0232s       ç›¸ç•¶
```

#### ç¥ç¶“ç¶²çµ¡è¨“ç·´æ¸¬è©¦
- æ•¸æ“šé›†: 1000å€‹æ¨£æœ¬ï¼Œ10ç¶­è¼¸å…¥ï¼Œ1ç¶­è¼¸å‡º
- æ¨¡å‹: å–®å±¤ç·šæ€§ç¶²çµ¡
- è¨“ç·´è¼ªæ•¸: 10
- æœ€çµ‚æå¤±: ~0.8 (éš¨æ©Ÿåˆå§‹åŒ–)

#### ComfyUIç¯€é»æ¸¬è©¦
- âœ… ç·šæ€§å±¤: è¼¸å…¥(2,10) â†’ è¼¸å‡º(2,5)
- âœ… æ¿€æ´»å‡½æ•¸: ReLU/Sigmoid/Tanh æ­£å¸¸å·¥ä½œ
- âœ… æå¤±å‡½æ•¸: MSE=1.1366, MAE=0.7949
- âœ… å¼µé‡é‹ç®—: åŠ æ³•/ä¹˜æ³•/çŸ©é™£ä¹˜æ³•æ­£å¸¸

## ğŸŒŸ å„ªå‹¢ç‰¹é»

### 1. ç„¡é©…å‹•ä¾è³´
- ä¸éœ€è¦CUDAã€ROCmæˆ–å…¶ä»–GPUé©…å‹•
- é©ç”¨æ–¼ä»»ä½•ç¡¬ä»¶ç’°å¢ƒ
- è§£æ±ºé©…å‹•å…¼å®¹æ€§å•é¡Œ

### 2. è¼•é‡ç´šå¯¦ç¾
- ç´”Python + NumPy
- æ˜“æ–¼ç†è§£å’Œä¿®æ”¹
- ä½å…§å­˜ä½”ç”¨

### 3. é«˜åº¦å¯æ“´å±•
- æ¨¡å¡ŠåŒ–è¨­è¨ˆ
- æ˜“æ–¼æ·»åŠ æ–°æ“ä½œ
- æ”¯æŒè‡ªå®šç¾©å„ªåŒ–

### 4. æ•™è‚²åƒ¹å€¼
- å­¸ç¿’æ·±åº¦å­¸ç¿’åº•å±¤å¯¦ç¾
- ç†è§£å¼µé‡æ“ä½œåŸç†
- å¯¦è¸è‡ªå®šç¾©æ¡†æ¶é–‹ç™¼

### 5. è·¨å¹³å°å…¼å®¹
- Windows/Linux/macOS
- Intel/AMD CPU
- å„ç¨®GPUç¡¬ä»¶

## âš ï¸ å±€é™æ€§

### 1. æ€§èƒ½é™åˆ¶
- åŸºæ–¼CPUè¨ˆç®—ï¼Œç„¡æ³•ç™¼æ®GPUä¸¦è¡Œå„ªå‹¢
- å¤§è¦æ¨¡è¨ˆç®—æ•ˆç‡ä¸å¦‚å„ªåŒ–åº«
- å…§å­˜å¸¶å¯¬å—é™æ–¼ç³»çµ±ç¸½ç·š

### 2. åŠŸèƒ½ä¸å®Œæ•´
- ç¼ºå°‘è‡ªå‹•å¾®åˆ†åŠŸèƒ½
- æœ‰é™çš„å„ªåŒ–å™¨æ”¯æŒ
- éƒ¨åˆ†é«˜ç´šæ“ä½œæœªå¯¦ç¾

### 3. ç”Ÿç”¢ç’°å¢ƒè€ƒæ…®
- ä¸»è¦ç”¨æ–¼æ¦‚å¿µé©—è­‰
- ç”Ÿç”¢ç’°å¢ƒå»ºè­°ä½¿ç”¨å„ªåŒ–åº«
- å¯èƒ½å­˜åœ¨æ•¸å€¼ç²¾åº¦å·®ç•°

## ğŸ”® æ“´å±•æ–¹å‘

### 1. ç¡¬ä»¶åŠ é€Ÿé›†æˆ
```python
# å¯èƒ½çš„æ“´å±•æ–¹å‘
class GPUAcceleratedBackend:
    def __init__(self):
        self.use_cuda = False
        self.use_opencl = True  # æˆ–è€… Vulkan, Metal ç­‰

    def matmul(self, a, b):
        if self.use_opencl:
            return opencl_matmul(a, b)
        else:
            return numpy_matmul(a, b)
```

### 2. è‡ªå‹•å¾®åˆ†å¯¦ç¾
```python
class AutogradTensor(CustomTensor):
    def __init__(self, data, requires_grad=False):
        super().__init__(data)
        self.requires_grad = requires_grad
        self.grad = None
        self.grad_fn = None

    def backward(self):
        # å¯¦ç¾åå‘å‚³æ’­
        pass
```

### 3. æ›´å¤šç¥ç¶“ç¶²çµ¡å±¤
- BatchNorm2d: æ‰¹æ­¸ä¸€åŒ–
- Dropout: ä¸Ÿæ£„å±¤
- LSTM/GRU: å¾ªç’°ç¥ç¶“ç¶²çµ¡
- Attention: æ³¨æ„åŠ›æ©Ÿåˆ¶

### 4. å„ªåŒ–å™¨å¯¦ç¾
```python
class CustomAdam:
    def __init__(self, parameters, lr=0.001):
        self.parameters = parameters
        self.lr = lr
        self.m = {}  # ä¸€éšçŸ©
        self.v = {}  # äºŒéšçŸ©

    def step(self):
        # Adamæ›´æ–°é‚è¼¯
        pass
```

### 5. é‡åŒ–æ”¯æŒ
- INT8é‡åŒ–
- å‹•æ…‹é‡åŒ–
- é‡åŒ–æ„ŸçŸ¥è¨“ç·´

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. æ¨¡çµ„å°å…¥éŒ¯èª¤
```
ModuleNotFoundError: No module named 'pytorch_custom_backend'
```
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# ç¢ºä¿è·¯å¾‘æ­£ç¢º
export PYTHONPATH=$PYTHONPATH:/path/to/pytorch-custom-backend
```

#### 2. ComfyUIç¯€é»ä¸é¡¯ç¤º
**æª¢æŸ¥æ­¥é©Ÿ**:
1. ç¢ºèªæ–‡ä»¶ä½ç½®: `ComfyUI/custom_nodes/pytorch_custom_nodes.py`
2. é‡å•ŸComfyUIæœå‹™å™¨
3. æª¢æŸ¥æ§åˆ¶å°éŒ¯èª¤ä¿¡æ¯
4. é©—è­‰Pythonè·¯å¾‘è¨­ç½®

#### 3. æ€§èƒ½å•é¡Œ
**å„ªåŒ–å»ºè­°**:
1. ä½¿ç”¨NumPyçš„å‘é‡åŒ–æ“ä½œ
2. é¿å…Pythonå¾ªç’°
3. è€ƒæ…®ä½¿ç”¨Numba JITç·¨è­¯
4. å°æ–¼å¤§çŸ©é™£è€ƒæ…®åˆ†å¡Šè¨ˆç®—

#### 4. å…§å­˜éŒ¯èª¤
```
MemoryError: Unable to allocate array
```
**è§£æ±ºæ–¹æ¡ˆ**:
1. æ¸›å°‘æ‰¹æ¬¡å¤§å°
2. ä½¿ç”¨æ›´å°çš„æ•¸æ“šé¡å‹ (float32 -> float16)
3. å¯¦ç¾åˆ†æ‰¹è™•ç†
4. æª¢æŸ¥ç³»çµ±å…§å­˜ä½¿ç”¨æƒ…æ³

### èª¿è©¦æŠ€å·§

#### å•Ÿç”¨è©³ç´°æ—¥èªŒ
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# åœ¨ä»£ç¢¼ä¸­æ·»åŠ èª¿è©¦ä¿¡æ¯
logger = logging.getLogger(__name__)
logger.debug(f"Tensor shape: {tensor.shape}")
```

#### æ€§èƒ½åˆ†æ
```python
import time
import cProfile

def profile_function(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"{func.__name__} took {end_time - start_time:.4f} seconds")
        return result
    return wrapper

@profile_function
def my_computation():
    # æ‚¨çš„è¨ˆç®—ä»£ç¢¼
    pass
```

## ğŸ“š åƒè€ƒè³‡æº

### ç›¸é—œé …ç›®
- [PyTorch Custom Operators](https://pytorch.org/tutorials/advanced/cpp_custom_ops.html)
- [NumPy Documentation](https://numpy.org/doc/)
- [ComfyUI Custom Nodes Guide](https://github.com/comfyanonymous/ComfyUI#custom-nodes)

### å­¸ç¿’è³‡æº
- [Deep Learning from Scratch](https://www.oreilly.com/library/view/deep-learning-from/9781492041405/)
- [PyTorch Internals](https://pytorch.org/docs/stable/internals.html)
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)

## ğŸ¤ è²¢ç»æŒ‡å—

æ­¡è¿æäº¤Issueå’ŒPull Requestï¼

### é–‹ç™¼è¨­ç½®
```bash
git clone <repository-url>
cd pytorch-custom-backend
pip install -r requirements-dev.txt
```

### æ¸¬è©¦é‹è¡Œ
```bash
python -m pytest tests/
python pytorch_custom_demo.py
```

### ä»£ç¢¼é¢¨æ ¼
- éµå¾ªPEP 8
- æ·»åŠ é¡å‹æç¤º
- ç·¨å¯«æ–‡æª”å­—ç¬¦ä¸²
- åŒ…å«å–®å…ƒæ¸¬è©¦

## ğŸ“„ è¨±å¯è­‰

MIT License - è©³è¦‹LICENSEæ–‡ä»¶

---

**æ³¨æ„**: æ­¤æ–¹æ¡ˆä¸»è¦ç”¨æ–¼å­¸ç¿’å’Œç ”ç©¶ç›®çš„ã€‚ç”Ÿç”¢ç’°å¢ƒå»ºè­°ä½¿ç”¨ç¶“éå„ªåŒ–çš„æ·±åº¦å­¸ç¿’æ¡†æ¶å¦‚PyTorchã€TensorFlowç­‰ã€‚

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹éš¨æ™‚è¯ç¹«ï¼ ğŸš€